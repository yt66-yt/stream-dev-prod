package com.stream.realtime.lululemon.uster;

import com.alibaba.fastjson2.JSON;
import com.alibaba.fastjson2.JSONObject;
import com.stream.core.EnvironmentSettingUtils;
import com.stream.realtime.lululemon.flinkcomment.util.IKAnalyzerUtil;
import com.ververica.cdc.connectors.sqlserver.SqlServerSource;
import com.ververica.cdc.debezium.DebeziumSourceFunction;
import com.ververica.cdc.debezium.JsonDebeziumDeserializationSchema;
import org.apache.flink.api.common.state.MapStateDescriptor;
import org.apache.flink.api.common.state.ReadOnlyBroadcastState;
import org.apache.flink.api.common.typeinfo.Types;
import org.apache.flink.streaming.api.datastream.BroadcastStream;
import org.apache.flink.streaming.api.datastream.DataStreamSource;
import org.apache.flink.streaming.api.datastream.KeyedStream;
import org.apache.flink.streaming.api.datastream.SingleOutputStreamOperator;
import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;
import org.apache.flink.streaming.api.functions.co.KeyedBroadcastProcessFunction;
import org.apache.flink.streaming.connectors.kafka.FlinkKafkaProducer;
import org.apache.flink.streaming.connectors.kafka.KafkaSerializationSchema;
import org.apache.flink.util.Collector;
import org.apache.kafka.clients.admin.AdminClient;
import org.apache.kafka.clients.admin.AdminClientConfig;
import org.apache.kafka.clients.admin.NewTopic;
import org.apache.kafka.clients.producer.ProducerRecord;
import org.apache.kafka.common.config.TopicConfig;

import javax.annotation.Nullable;
import java.nio.charset.StandardCharsets;
import java.nio.file.Files;
import java.nio.file.Paths;
import java.util.*;
import java.util.concurrent.TimeUnit;
import java.util.stream.Collectors;

public class CommentAnalysisKafkaIK {

    /**
     * ç¡®ä¿Kafkaä¸»é¢˜å­˜åœ¨
     */
    private static void ensureKafkaTopicExists(String bootstrapServers, String topicName) {
        Properties adminProps = new Properties();
        adminProps.put(AdminClientConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers);
        adminProps.put(AdminClientConfig.REQUEST_TIMEOUT_MS_CONFIG, 30000);

        try (AdminClient adminClient = AdminClient.create(adminProps)) {
            Set<String> topics = adminClient.listTopics().names().get(30000, TimeUnit.MILLISECONDS);

            if (!topics.contains(topicName)) {
                System.out.println("âš ï¸  Kafkaä¸»é¢˜ '" + topicName + "' ä¸å­˜åœ¨ï¼Œæ­£åœ¨åˆ›å»º...");

                Map<String, String> topicConfigs = new HashMap<>();
                topicConfigs.put(TopicConfig.RETENTION_MS_CONFIG, "604800000"); // 7å¤©ä¿ç•™
                topicConfigs.put(TopicConfig.CLEANUP_POLICY_CONFIG, TopicConfig.CLEANUP_POLICY_DELETE);
                topicConfigs.put(TopicConfig.MAX_MESSAGE_BYTES_CONFIG, "10485760"); // 10MBæœ€å¤§æ¶ˆæ¯å¤§å°

                NewTopic newTopic = new NewTopic(topicName, 3, (short) 1)
                        .configs(topicConfigs);

                adminClient.createTopics(Collections.singletonList(newTopic)).all().get(30000, TimeUnit.MILLISECONDS);
                System.out.println("âœ…  Kafkaä¸»é¢˜ '" + topicName + "' åˆ›å»ºæˆåŠŸï¼Œåˆ†åŒºæ•°: 3, å‰¯æœ¬å› å­: 1");
            } else {
                System.out.println("âœ…  Kafkaä¸»é¢˜ '" + topicName + "' å·²å­˜åœ¨");
            }
        } catch (Exception e) {
            System.err.println("âŒ  æ£€æŸ¥/åˆ›å»ºKafkaä¸»é¢˜å¤±è´¥: " + e.getMessage());
            System.out.println("âš ï¸  è¯·ç¡®ä¿Kafka brokeré…ç½®å…è®¸è‡ªåŠ¨åˆ›å»ºä¸»é¢˜ï¼Œæˆ–æ‰‹åŠ¨åˆ›å»ºä¸»é¢˜: " + topicName);
        }
    }

    public static void main(String[] args) throws Exception {
        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();

        // é…ç½®å‚æ•°
        env.setParallelism(1);
        env.disableOperatorChaining();
        env.enableCheckpointing(10000);
        EnvironmentSettingUtils.defaultParameter(env);

        // ç¡®ä¿Kafkaä¸»é¢˜å­˜åœ¨
        String bootstrapServers = "172.24.158.53:9092";
        String topicName = "realtime_v3_order_comment";
        ensureKafkaTopicExists(bootstrapServers, topicName);

        // SQL Server CDC æº
        Properties debeziumProps = new Properties();
        debeziumProps.put("decimal.handling.mode", "string");

        DebeziumSourceFunction<String> sqlServerSource =
                SqlServerSource.<String>builder()
                        .hostname("192.168.200.30")
                        .port(1433)
                        .database("realtime_v3")
                        .tableList("dbo.jd_product_comments")
                        .username("sa")
                        .password("zhangyihao@123")
                        .debeziumProperties(debeziumProps)
                        .deserializer(new JsonDebeziumDeserializationSchema())
                        .build();

        DataStreamSource<String> sourceStream = env.addSource(sqlServerSource, "SqlServer-Source");

        // è¯»å–æ•æ„Ÿè¯æ–‡ä»¶
        String p0SensitiveWordFile = "D:\\idealwj\\stream-dev-prod\\stream-realtime\\src\\main\\java\\com\\stream\\realtime\\lululemon\\flinkcomment\\suspected-sensitive-words.txt";
        List<String> p0SensitiveWords = Files.lines(Paths.get(p0SensitiveWordFile))
                .map(String::trim)
                .filter(line -> !line.isEmpty())
                .collect(Collectors.toList());

        String p1SensitiveWordFile = "D:\\idealwj\\stream-dev-prod\\stream-realtime\\src\\main\\java\\com\\stream\\realtime\\lululemon\\flinkcomment\\p1-sensitive-words.txt";
        List<String> p1SensitiveWords = Files.lines(Paths.get(p1SensitiveWordFile))
                .map(String::trim)
                .filter(line -> !line.isEmpty())
                .collect(Collectors.toList());

        System.out.println("å·²åŠ è½½P0æ•æ„Ÿè¯æ•°é‡: " + p0SensitiveWords.size());
        System.out.println("å·²åŠ è½½P1æ•æ„Ÿè¯æ•°é‡: " + p1SensitiveWords.size());

        if (!p0SensitiveWords.isEmpty()) {
            System.out.println("P0æ•æ„Ÿè¯ç¤ºä¾‹: " + p0SensitiveWords.subList(0, Math.min(5, p0SensitiveWords.size())));
        }
        if (!p1SensitiveWords.isEmpty()) {
            System.out.println("P1æ•æ„Ÿè¯ç¤ºä¾‹: " + p1SensitiveWords.subList(0, Math.min(5, p1SensitiveWords.size())));
        }

        // åˆå¹¶æ‰€æœ‰æ•æ„Ÿè¯ç”¨äºé¢„åŠ è½½
        List<String> allSensitiveWords = new ArrayList<>();
        allSensitiveWords.addAll(p0SensitiveWords);
        allSensitiveWords.addAll(p1SensitiveWords);

        // é¢„åŠ è½½æ•æ„Ÿè¯åˆ°åˆ†è¯å™¨
        IKAnalyzerUtil.preloadSensitiveWords(allSensitiveWords);
        System.out.println("âœ… æ•æ„Ÿè¯é¢„åŠ è½½å®Œæˆï¼Œæ€»æ•°: " + allSensitiveWords.size());

        // æµ‹è¯•åˆ†è¯æ•ˆæœ
        testIKAnalyzer();

        // åˆ›å»ºåŒ…å«çº§åˆ«ä¿¡æ¯çš„æ•æ„Ÿè¯åˆ—è¡¨
        List<SensitiveWord> allSensitiveWordsWithLevel = new ArrayList<>();
        for (String word : p0SensitiveWords) {
            allSensitiveWordsWithLevel.add(new SensitiveWord(word, "P0"));
        }
        for (String word : p1SensitiveWords) {
            allSensitiveWordsWithLevel.add(new SensitiveWord(word, "P1"));
        }

        MapStateDescriptor<String, SensitiveWord> sensitiveStateDescriptor =
                new MapStateDescriptor<>("sensitiveWords", Types.STRING, Types.POJO(SensitiveWord.class));

        // åˆ›å»ºå¹¿æ’­æµåŒ…å«æ‰€æœ‰æ•æ„Ÿè¯
        BroadcastStream<SensitiveWord> broadcastWords = env.fromCollection(allSensitiveWordsWithLevel)
                .broadcast(sensitiveStateDescriptor);

        // æ•°æ®å¤„ç†æµç¨‹
        KeyedStream<String, String> keyedStream = sourceStream.keyBy(json -> {
            try {
                JSONObject obj = JSON.parseObject(json);
                JSONObject after = obj.getJSONObject("after");
                return after != null ? after.getString("user_id") : "unknown";
            } catch (Exception e) {
                return "unknown";
            }
        });

        // è¿æ¥å¹¿æ’­æµè¿›è¡Œå¤„ç†
        SingleOutputStreamOperator<CommentResult> processedStream = keyedStream
                .connect(broadcastWords)
                .process(new CommentLevelProcessor())
                .name("comment-level-processor");

        // Kafka é…ç½®
        Properties kafkaProps = new Properties();
        kafkaProps.setProperty("bootstrap.servers", bootstrapServers);
        kafkaProps.setProperty("batch.size", "16384");
        kafkaProps.setProperty("linger.ms", "5");
        kafkaProps.setProperty("buffer.memory", "33554432");
        kafkaProps.setProperty("acks", "1"); // ç¡®ä¿æ¶ˆæ¯è¢«ç¡®è®¤
        kafkaProps.setProperty("retries", "3"); // é‡è¯•æ¬¡æ•°
        kafkaProps.setProperty("request.timeout.ms", "30000"); // è¯·æ±‚è¶…æ—¶æ—¶é—´

        // åˆ›å»ºKafka Sink
        FlinkKafkaProducer<CommentResult> kafkaSink = new FlinkKafkaProducer<>(
                topicName,
                new CommentResultKafkaSerializer(),
                kafkaProps,
                FlinkKafkaProducer.Semantic.AT_LEAST_ONCE
        );

        // å†™å…¥ Kafka
        processedStream.addSink(kafkaSink)
                .name("kafka-comment-sink");

        System.out.println("ğŸš€ å¼€å§‹æ‰§è¡ŒFlinkä½œä¸š: SQLServer Comment to Kafka with Level Classification");
        env.execute("SQLServer Comment to Kafka with Level Classification");
    }

    /**
     * Kafkaåºåˆ—åŒ–å™¨ - å°†CommentResultå¯¹è±¡åºåˆ—åŒ–ä¸ºJSONå­—ç¬¦ä¸²
     */
    public static class CommentResultKafkaSerializer implements KafkaSerializationSchema<CommentResult> {

        @Override
        public ProducerRecord<byte[], byte[]> serialize(CommentResult element, @Nullable Long timestamp) {
            try {
                // å°†CommentResultå¯¹è±¡è½¬æ¢ä¸ºJSONå­—ç¬¦ä¸²
                String json = JSON.toJSONString(element);

                // åˆ›å»ºProducerRecordï¼Œkeyä½¿ç”¨user_idï¼Œvalueä¸ºJSONå­—ç¬¦ä¸²
                String key = element.getUser_id();  // ä¿®æ­£ï¼šä½¿ç”¨getUser_id()è€Œä¸æ˜¯getUserid()
                return new ProducerRecord<>(
                        "realtime_v3_order_comment",
                        key != null ? key.getBytes(StandardCharsets.UTF_8) : null,
                        json.getBytes(StandardCharsets.UTF_8)
                );
            } catch (Exception e) {
                System.err.println("âŒ åºåˆ—åŒ–CommentResultå¤±è´¥: " + e.getMessage());
                // è¿”å›é”™è¯¯ä¿¡æ¯ï¼Œé¿å…æ•°æ®ä¸¢å¤±
                String errorJson = "{\"error\":\"serialization_failed\",\"message\":\"" + e.getMessage() + "\"}";
                return new ProducerRecord<>(
                        "realtime_v3_order_comment",
                        null,
                        errorJson.getBytes(StandardCharsets.UTF_8)
                );
            }
        }
    }

    /**
     * æµ‹è¯•åˆ†è¯å™¨æ•ˆæœ
     */
    private static void testIKAnalyzer() {
        System.out.println("=== IKåˆ†è¯å™¨æµ‹è¯• ===");

        String testText = "è¿™æ¬¾å¤¹å…‹è´¨é‡ä¸€èˆ¬ï¼Œæ”¶çº³è®¾è®¡å…±é“²å…šä¹Ÿä¸æ–¹ä¾¿ï¼Œæ€§ä»·æ¯”ä¸é«˜ã€‚";
        System.out.println("æµ‹è¯•æ–‡æœ¬: " + testText);

        // æµ‹è¯•åˆ†è¯æ•ˆæœ
        List<String> segments = IKAnalyzerUtil.smartSegments(testText);
        System.out.println("åˆ†è¯ç»“æœ: " + segments);

        // æµ‹è¯•æ•æ„Ÿè¯æ£€æµ‹
        List<String> testP0Words = Arrays.asList("å…±é“²å…š", "æµ‹è¯•è¯");
        List<String> testP1Words = Arrays.asList("è´¨é‡ä¸€èˆ¬", "ä¸æ–¹ä¾¿");

        Map<String, List<String>> result = IKAnalyzerUtil.detectSensitiveWordsWithLevel(
                testText, testP0Words, testP1Words);

        System.out.println("P0åŒ¹é…: " + result.get("P0"));
        System.out.println("P1åŒ¹é…: " + result.get("P1"));
        System.out.println("=== æµ‹è¯•ç»“æŸ ===\n");
    }

    /**
     * æ•æ„Ÿè¯ç±»ï¼ŒåŒ…å«è¯è¯­å’Œçº§åˆ«ä¿¡æ¯
     */
    public static class SensitiveWord {
        private String word;
        private String level;  // P0 æˆ– P1

        public SensitiveWord() {
            // é»˜è®¤æ„é€ å‡½æ•°ç”¨äºåºåˆ—åŒ–
        }

        public SensitiveWord(String word, String level) {
            this.word = word;
            this.level = level;
        }

        public String getWord() { return word; }
        public void setWord(String word) { this.word = word; }

        public String getLevel() { return level; }
        public void setLevel(String level) { this.level = level; }

        @Override
        public String toString() {
            return "SensitiveWord{word='" + word + "', level='" + level + "'}";
        }
    }

    /**
     * è¯„è®ºç»“æœç±» - ä¿æŒä¸åŸæ¥Dorisè¡¨ç›¸åŒçš„ç»“æ„
     */
    public static class CommentResult {
        private String user_id;
        private String orderid;
        private String username;
        private String comment;
        private int isBlack;
        private String commentLevel;
        private List<String> sensitiveWords;

        public CommentResult() {}

        public CommentResult(String user_id, String orderid, String username, String comment,
                             int isBlack, String commentLevel, List<String> sensitiveWords) {
            this.user_id = user_id;
            this.orderid = orderid;
            this.username = username;
            this.comment = comment;
            this.isBlack = isBlack;
            this.commentLevel = commentLevel;
            this.sensitiveWords = sensitiveWords;
        }

        // ä¿®æ­£ï¼šgetteræ–¹æ³•åä¸å­—æ®µåä¿æŒä¸€è‡´
        public String getUser_id() { return user_id; }
        public void setUser_id(String user_id) { this.user_id = user_id; }

        public String getOrderid() { return orderid; }
        public void setOrderid(String orderid) { this.orderid = orderid; }

        public String getUsername() { return username; }
        public void setUsername(String username) { this.username = username; }

        public String getComment() { return comment; }
        public void setComment(String comment) { this.comment = comment; }

        public int getIsBlack() { return isBlack; }
        public void setIsBlack(int isBlack) { this.isBlack = isBlack; }

        public String getCommentLevel() { return commentLevel; }
        public void setCommentLevel(String commentLevel) { this.commentLevel = commentLevel; }

        public List<String> getSensitiveWords() { return sensitiveWords; }
        public void setSensitiveWords(List<String> sensitiveWords) { this.sensitiveWords = sensitiveWords; }

        @Override
        public String toString() {
            return "CommentResult{" +
                    "user_id='" + user_id + '\'' +
                    ", orderid='" + orderid + '\'' +
                    ", username='" + username + '\'' +
                    ", comment='" + comment + '\'' +
                    ", isBlack=" + isBlack +
                    ", commentLevel='" + commentLevel + '\'' +
                    ", sensitiveWords=" + sensitiveWords +
                    '}';
        }
    }

    /**
     * è¯„è®ºåˆ†çº§å¤„ç†ç±» - ä¿æŒåŸæœ‰é€»è¾‘ä¸å˜
     */
    public static class CommentLevelProcessor extends KeyedBroadcastProcessFunction<String, String, SensitiveWord, CommentResult> {

        private MapStateDescriptor<String, SensitiveWord> sensitiveStateDescriptor =
                new MapStateDescriptor<>("sensitiveWords", Types.STRING, Types.POJO(SensitiveWord.class));

        @Override
        public void processElement(String commentJson, ReadOnlyContext ctx, Collector<CommentResult> out) throws Exception {
            try {
                JSONObject obj = JSON.parseObject(commentJson);
                JSONObject after = obj.getJSONObject("after");
                if (after == null) {
                    return;
                }

                // æå–è¯„è®ºå†…å®¹
                String commentText = extractCommentText(after.getString("comment"));
                if (commentText == null) {
                    commentText = "";
                }

                // è¯„è®ºåˆ†çº§æ£€æµ‹ï¼ˆä½¿ç”¨ä¼˜åŒ–çš„æ£€æµ‹æ–¹æ³•ï¼‰
                CommentLevelResult levelResult = detectCommentLevelOptimized(commentText, ctx);

                // æ„å»ºè¾“å‡ºç»“æœ
                CommentResult result = buildCommentResult(after, commentText, levelResult);
                out.collect(result);

                // æ‰“å°åˆ†çº§ç»“æœ
                if (!"P2".equals(levelResult.getLevel())) {
                    System.out.println("ğŸ“Š è¯„è®ºåˆ†çº§ç»“æœ: " + levelResult.getLevel() +
                            ", æ•æ„Ÿè¯: " + levelResult.getSensitiveWords() +
                            ", ç”¨æˆ·: " + after.getString("user_id"));
                }

            } catch (Exception e) {
                System.err.println("âŒ å¤„ç†æ•°æ®å¤±è´¥: " + e.getMessage());
                e.printStackTrace();
            }
        }

        /**
         * ä½¿ç”¨çº¯åˆ†è¯åŒ¹é…çš„æ•æ„Ÿè¯æ£€æµ‹æ–¹æ³•
         */
        private CommentLevelResult detectCommentLevelOptimized(String comment, ReadOnlyContext ctx) throws Exception {
            List<String> allMatchedWords = new ArrayList<>();
            String commentLevel = "P2";
            boolean hasP0Word = false;
            boolean hasP1Word = false;

            ReadOnlyBroadcastState<String, SensitiveWord> broadcastState =
                    ctx.getBroadcastState(sensitiveStateDescriptor);

            // æå–P0å’ŒP1æ•æ„Ÿè¯
            List<String> p0Words = new ArrayList<>();
            List<String> p1Words = new ArrayList<>();

            for (Map.Entry<String, SensitiveWord> entry : broadcastState.immutableEntries()) {
                SensitiveWord sensitiveWord = entry.getValue();
                if ("P0".equals(sensitiveWord.getLevel())) {
                    p0Words.add(sensitiveWord.getWord());
                } else if ("P1".equals(sensitiveWord.getLevel())) {
                    p1Words.add(sensitiveWord.getWord());
                }
            }

            // ä½¿ç”¨çº¯åˆ†è¯åŒ¹é…
            Map<String, List<String>> detectionResult =
                    IKAnalyzerUtil.detectSensitiveWordsWithLevel(comment, p0Words, p1Words);

            List<String> matchedP0Words = detectionResult.get("P0");
            List<String> matchedP1Words = detectionResult.get("P1");

            // è®°å½•åŒ¹é…çš„æ•æ„Ÿè¯
            if (matchedP0Words != null && !matchedP0Words.isEmpty()) {
                hasP0Word = true;
                allMatchedWords.addAll(matchedP0Words);
            } else if (matchedP1Words != null && !matchedP1Words.isEmpty()) {
                hasP1Word = true;
                allMatchedWords.addAll(matchedP1Words);
            }

            // è°ƒè¯•ä¿¡æ¯
            if (!allMatchedWords.isEmpty()) {
                System.out.println("ğŸ¯ åˆ†è¯åŒ¹é…ç»“æœ:");
                System.out.println("   è¯„è®º: " + (comment.length() > 50 ? comment.substring(0, 50) + "..." : comment));
                System.out.println("   åŒ¹é…çš„æ•æ„Ÿè¯: " + allMatchedWords);
            }

            // ç¡®å®šè¯„è®ºçº§åˆ«
            if (hasP0Word) {
                commentLevel = "P0";
            } else if (hasP1Word) {
                commentLevel = "P1";
            }

            return new CommentLevelResult(commentLevel, allMatchedWords);
        }

        /**
         * æ„å»ºè¯„è®ºç»“æœ
         */
        private CommentResult buildCommentResult(JSONObject after, String commentText, CommentLevelResult levelResult) {
            String username = after.getString("user_name");
            if (username == null) {
                username = "unknown_user";
            }

            return new CommentResult(
                    after.getString("user_id"),      // user_id
                    after.getString("order_id"),     // orderid
                    username,                        // username
                    commentText,                     // comment
                    levelResult.getLevel().equals("P0") ? 1 : 0,  // is_black
                    levelResult.getLevel(),          // comment_level
                    levelResult.getSensitiveWords()  // sensitive_words
            );
        }

        private String extractCommentText(String commentField) {
            if (commentField == null || commentField.trim().isEmpty()) {
                return "";
            }
            try {
                JSONObject commentJson = JSON.parseObject(commentField);
                if (commentJson.containsKey("comment")) {
                    return commentJson.getString("comment");
                }
                return commentField;
            } catch (Exception e) {
                return commentField;
            }
        }

        @Override
        public void processBroadcastElement(SensitiveWord sensitiveWord, Context ctx, Collector<CommentResult> out) throws Exception {
            ctx.getBroadcastState(sensitiveStateDescriptor).put(sensitiveWord.getWord(), sensitiveWord);
        }
    }

    /**
     * è¯„è®ºåˆ†çº§ç»“æœç±»
     */
    public static class CommentLevelResult {
        private String level;  // P0, P1, P2
        private List<String> sensitiveWords; // åŒ¹é…çš„æ•æ„Ÿè¯åˆ—è¡¨

        public CommentLevelResult(String level, List<String> sensitiveWords) {
            this.level = level;
            this.sensitiveWords = sensitiveWords;
        }

        public String getLevel() { return level; }
        public List<String> getSensitiveWords() { return sensitiveWords; }
    }
}